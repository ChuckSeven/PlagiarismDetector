Diese File besteht aus A,B,F,G,H,I,E
A
This may be visualized as restricting the sample space to B. The logic behind this equation is that if the outcomes are restricted to B, this set serves as the new sample space.
Note that this is a definition but not a theoretical result. We just denote the quantity P(A\cap B)/P(B) as P(A|B) and call it the conditional probability of A given B.
As an axiom of probability[edit]
Some authors, such as De Finetti, prefer to introduce conditional probability as an axiom of probability:
P(A \cap B) = P(A|B)P(B)
Although mathematically equivalent, this may be preferred philosophically; under major probability interpretations such as the subjective theory, conditional probability is considered a primitive entity. Further, this "multiplication axiom" introduces a symmetry with the summation axiom for mutually exclusive events:[4]
-----
B
Definition with s-algebra[edit]
If P(B) = 0, then the simple definition of P(A|B) is undefined. However, it is possible to define a conditional probability with respect to a s-algebra of such events (such as those arising from a continuous random variable).
For example, if X and Y are non-degenerate and jointly continuous random variables with density ÉX,Y(x, y) then, if B has positive measure,

P(X \in A \mid Y \in B) =
\frac{\int_{y\in B}\int_{x\in A} f_{X,Y}(x,y)\,dx\,dy}{\int_{y\in B}\int_{x\in\Omega} f_{X,Y}(x,y)\,dx\,dy} .
The case where B has zero measure can only be dealt with directly in the case that B = {y0}, representing a single point, in which case

P(X \in A \mid Y = y_0) = \frac{\int_{x\in A} f_{X,Y}(x,y_0)\,dx}{\int_{x\in\Omega} f_{X,Y}(x,y_0)\,dx} .
-----
F
In probability theory, Boole's inequality, also known as the union bound, says that for any finite or countable set of events, the probability that at least one of the events happens is no greater than the sum of the probabilities of the individual events. Boole's inequality is named after George Boole.
Formally, for a countable set of events A1, A2, A3, ..., we have
{\mathbb P}\biggl(\bigcup_{i} A_i\biggr) \le \sum_i {\mathbb P}(A_i).
In measure-theoretic terms, Boole's inequality follows from the fact that a measure (and certainly any probability measure) is s-sub-additive.

-----
G
Boole's inequality may be proved for finite collections of events using the method of induction.
For the n=1 case, it follows that
\mathbb P(A_1) \le \mathbb P(A_1).
For the case n, we have
{\mathbb P}\biggl(\bigcup_{i=_1}^{n} A_i\biggr) \le \sum_{i=_1}^{n} {\mathbb P}(A_i).
Since \mathbb P(A \cup B) = \mathbb P(A) + \mathbb P(B) - \mathbb P(A \cap B), and because the union operation is associative, we have
{\mathbb P}\biggl(\bigcup_{i=_1}^{n+1} A_i\biggr) = {\mathbb P}\biggl(\bigcup_{i=_1}^n A_i\biggr) + \mathbb P(A_{n+1}) - {\mathbb P}\biggl(\bigcup_{i=_1}^n A_i \cap A_{n+1}\biggr).
Since
{\mathbb P}\biggl(\bigcup_{i=_1}^n A_i \cap A_{n+1}\biggr) \ge 0,
by the first axiom of probability, we have
------
H
Bonferroni inequalities[edit]
Boole's inequality may be generalised to find upper and lower bounds on the probability of finite unions of events. These bounds are known as Bonferroni inequalities, after Carlo Emilio Bonferroni, see Bonferroni (1936).
Define
S_1 := \sum_{i=1}^n {\mathbb P}(A_i),
and
S_2 := \sum_{1\le i<j\le n} {\mathbb P}(A_i \cap A_j),
as well as
S_k := \sum_{1\le i_1<\cdots<i_k\le n} {\mathbb P}(A_{i_1}\cap \cdots \cap A_{i_k} )
for all integers k in {3, ..., n}.
Then, for odd k in {1, ..., n},
{\mathbb P}\biggl( \bigcup_{i=1}^n A_i \biggr) \le \sum_{j=1}^k (-1)^{j-1} S_j,
------
I
References[edit]
Bonferroni, Carlo E. (1936), "Teoria statistica delle classi e calcolo delle probabilit‡", Pubbl. d. R. Ist. Super. di Sci. Econom. e Commerciali di Firenze (in Italian) 8: 1ñ62, Zbl 0016.41103
Dohmen, Klaus (2003), Improved Bonferroni Inequalities via Abstract Tubes. Inequalities and Identities of InclusionñExclusion Type, Lecture Notes in Mathematics 1826, Berlin: Springer-Verlag, pp. viii+113, ISBN 3-540-20025-8, MR 2019293, Zbl 1026.05009
Galambos, J·nos; Simonelli, Italo (1996), Bonferroni-Type Inequalities with Applications, Probability and Its Applications, New York: Springer-Verlag, pp. x+269, ISBN 0-387-94776-0, MR 1402242, Zbl 0869.60014
Galambos, J·nos (1977), "Bonferroni inequalities", Annals of Probability 5 (4): 577ñ581, doi:10.1214/aop/1176995765, JSTOR 2243081, MR 0448478, Zbl 0369.60018
Galambos, J·nos (2001), "Bonferroni inequalities", in Hazewinkel, Michiel, Encyclopedia of Mathematics, Springer, ISBN 978-1-55608-010-4
This article incorporates material from Bonferroni inequalities on PlanetMath, which is licensed under the Creative Commons Attribution/Share-Alike License.
----
E
\Pr(R \mid B \cap Y) = \Pr(R \mid Y).\,
Two random variables X and Y are conditionally independent given a third random variable Z if and only if they are independent in their conditional probability distribution given Z. That is, X and Y are conditionally independent given Z if and only if, given any value of Z, the probability distribution of X is the same for all values of Y and the probability distribution of Y is the same for all values of X.
Two events R and B are conditionally independent given a s-algebra S if
\Pr(R \cap B \mid \Sigma) = \Pr(R \mid \Sigma)\Pr(B \mid \Sigma)\ a.s.
where \Pr(A \mid \Sigma)  denotes the conditional expectation of the indicator function of the event A, \chi_A, given the sigma algebra \Sigma. That is,
\Pr(A \mid \Sigma) := \operatorname{E}[\chi_A\mid\Sigma].
Two random variables X and Y are conditionally independent given a s-algebra S if the above equation holds for all R in s(X) and B in s(Y).
